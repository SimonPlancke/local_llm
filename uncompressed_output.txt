<source type="local_directory" path="C:\Users\simon.plancke\OneDrive - Keyrus\Documents\repositories\SportsCompetition">
<file name="get_data\main.py">
from datetime import datetime
from pathlib import Path
import os

from src.api_methods import get_methods
from src.api_methods import authorize
from src.data_preprocessing import main as data_prep

# used to f.e set the limit of fetched activities (default - 30)
ACTIVITIES_PER_PAGE = 200
# current page number with activities
PAGE_NUMBER = 1


GET_ALL_ACTIVITIES_PARAMS = {
    'per_page': ACTIVITIES_PER_PAGE,
    'page': PAGE_NUMBER
}


def main():
    main_directory = os.path.dirname(os.path.realpath(__file__))
    token_directory = main_directory + '/refresh_tokens'
    for file in os.listdir(token_directory):
        # Get the name of the athlete from the file name
        athlete_name = Path(file).stem
        # Get the refresh_token from the file
        refresh_token =  open(f'{token_directory}/{file}', 'r').read()
        # Get the access token using the refresh token
        token:str = authorize.get_acces_token(refresh_token)
        # Get the Strava data from the athlete
        data:dict = get_methods.access_activity_data(token, params=GET_ALL_ACTIVITIES_PARAMS)
        df = data_prep.preprocess_data(data)
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        df.to_csv(Path(f'{main_directory}/data', f'{athlete_name}_{timestamp}.csv'), index=False)


def single_player():
    refresh_token =  "55d3df7944ef1d6ec57a2f11d1b8d91be23824d3" #open(f'{token_directory}/{file}', 'r').read()
    athlete_name = 'Ket_Kharashvili'
    main_directory = 'get_data'
    # Get the access token using the refresh token
    token:str = authorize.get_acces_token(refresh_token)
    # Get the Strava data from the athlete
    data:dict = get_methods.access_activity_data(token, params=GET_ALL_ACTIVITIES_PARAMS)
    df = data_prep.preprocess_data(data)
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    df.to_csv(Path(f'{main_directory}/data', f'{athlete_name}_{timestamp}.csv'), index=False)

if __name__ == '__main__':
    main()
    # single_player()
</file>
<file name="get_data\README.md">
# Strava Activity Data Retrieval using Python

This Python script allows you to retrieve your activity data from Strava's API and store it in a local .csv file

## Installation

1. Clone this repository to your local machine.

```bash
git clone https://github.com/yourusername/strava-activity-retrieval.git
cd strava-activity-retrieval
```


2. Install the required packages using pip.

```bash
pip install -r requirements.txt
```

## Configuration

1. Create a `.env` file in the project directory with the following content:

```
CLIENT_ID=XXXXXXXX
CLIENT_SECRET=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
REFRESH_TOKEN=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
```

Replace every field with your data.


## Usage

Run the Python script to retrieve your Strava activity data:

```bash
python main.py
```

Follow the on-screen instructions to authorize the application and retrieve your activity data. The data will be saved to a CSV file in the **data/** directory with current datetime suffix.


Happy analyzing your Strava activity data!

</file>
<file name="get_data\refresh_token.py">
response = {"token_type":"Bearer","expires_at":1708638285,"expires_in":21600,"refresh_token":"bff62ed8ee0a75fcb425b965f6b368ab30d47fb5","access_token":"a40ffd86257ad5fbf32dde29e9125108b1d3f2c8","athlete":{"id":73281514,"username":"plancke","resource_state":2,"firstname":"Simon","lastname":"Plancke","bio":'null',"city":'null',"state":'null',"country":'null',"sex":"M","premium":'false',"summit":'false',"created_at":"2020-12-02T18:05:10Z","updated_at":"2024-02-22T15:40:29Z","badge_type_id":0,"weight":0.0,"profile_medium":"https://graph.facebook.com/3557003947746255/picture?height=256\u0026width=256","profile":"https://graph.facebook.com/3557003947746255/picture?height=256\u0026width=256","friend":'null',"follower":'null'}}
print(response["refresh_token"])

</file>
<file name="get_data\requirements.txt">
environs==9.5.0
pandas==2.1.0
Requests==2.31.0

</file>
<file name="get_data\drop\Cédric_Smirnov.txt">
a218228fb473f8536e4f6833e3ef8c2706b657c4
</file>
<file name="get_data\refresh_tokens\Abdulrahman_Alrazaz.txt">
d8efdf058bdc11b970beb24fccf469d01667d634
</file>
<file name="get_data\refresh_tokens\Ana_Seoane-Ruiz.txt">
5341c698975a17c11f0608c1e4ddfe554df07893
</file>
<file name="get_data\refresh_tokens\Arthur-Nyns_Nyns.txt">
ae668994b72d9d88fa3b8e368ec1299fef8ddec6
</file>
<file name="get_data\refresh_tokens\Arthur_Vandecan.txt">
e4c1562cadbea4bd5c2a4716bd1b3f30e07dc4c7
</file>
<file name="get_data\refresh_tokens\Axel_Botton-Roulin.txt">
b2d2b424339d1ae51343e125b19630a2e0b67400
</file>
<file name="get_data\refresh_tokens\Ben_Curvers.txt">
24734fa8769e391d862d365205db87f92d8f9d93
</file>
<file name="get_data\refresh_tokens\Charline_Doyen.txt">
7e126aa75851c1e361b8f155a27ffe4fb0a74736
</file>
<file name="get_data\refresh_tokens\Clotilde_L.txt">
650dba793f501eda15e3c482f9e2e31d672bbb30
</file>
<file name="get_data\refresh_tokens\Danaë_Geurten.txt">
d69201d69519102b7526d66e400f510ae7c8b1a6
</file>
<file name="get_data\refresh_tokens\Elias_Van-Haver.txt">
ab88af3e280a34e121eea0f3b247717569a78f5a
</file>
<file name="get_data\refresh_tokens\Elonie_Standaert.txt">
9834f42c1299b48bb91162d1f51f7c5db261e2ee
</file>
<file name="get_data\refresh_tokens\Flavio_Marinello.txt">
ae84ca70d3897a91e282736492d3e58b7a5bcdd6
</file>
<file name="get_data\refresh_tokens\Florian_Ferrelli.txt">
25ef33b03d8cce8318be79d16d9626298e1ae236
</file>
<file name="get_data\refresh_tokens\Guillaume_Michaux.txt">
6983bdfe7117ed8e766e3db503ccbbc72c879db9
</file>
<file name="get_data\refresh_tokens\Hanri_Naudé.txt">
e107172760f730d31546dd9eb67070f56029ed2f
</file>
<file name="get_data\refresh_tokens\Hilde_Mosselmans.txt">
8fa4443ff53e6650ef415cd6c34e2e690e81a9ee
</file>
<file name="get_data\refresh_tokens\Hélène_Willekens.txt">
fcb62f170f135217d1d7ae9d11a93434855efda8
</file>
<file name="get_data\refresh_tokens\James_Applebee.txt">
1603770773b933b7cb5692a9d25515b641d180e4
</file>
<file name="get_data\refresh_tokens\JF_T'Serclaes.txt">
1cad30525d7033d1c18d00b4be40f16aa009f6bd
</file>
<file name="get_data\refresh_tokens\Karel_Dewitte.txt">
9128f4a910188abe4f3e13e94f18f86dfffa196b
</file>
<file name="get_data\refresh_tokens\Ket_Kharashvili.txt">
55d3df7944ef1d6ec57a2f11d1b8d91be23824d3
</file>
<file name="get_data\refresh_tokens\Kieran_Kelly.txt">
d62896d934bc4e7448b6046a04fbda55e9b0b98f
</file>
<file name="get_data\refresh_tokens\Laissa_Larbi.txt">
e7ca5b44a16d57f4828f692a55fa1f899df21682
</file>
<file name="get_data\refresh_tokens\Lisanza_Faccilongo.txt">
9ceeb55b43aa648023354fdd45259803efaf462d
</file>
<file name="get_data\refresh_tokens\Louis_Wellekens.txt">
802e08a8072c04ef5e5d13ccff889a0eb8ef2653
</file>
<file name="get_data\refresh_tokens\marine_Lafitau.txt">
b0a9bfa7ab40395bb56e99e0a75a219f5a3ff9eb
</file>
<file name="get_data\refresh_tokens\Mathieu_Pas.txt">
9956c154fd2e40e9c8b588cd4b50cf50dc5806ea
</file>
<file name="get_data\refresh_tokens\Maxime_Verheyen.txt">
432d73b01b87dd4507098bda05d5cb9edb8336fd
</file>
<file name="get_data\refresh_tokens\Morad_Masnaoui.txt">
803a62aae7d3067befc78df5af1ccea743051a3c
</file>
<file name="get_data\refresh_tokens\Nicolas_Charpentier.txt">
4b06578310b45109c8508c491aa521099e10aacb
</file>
<file name="get_data\refresh_tokens\Philip_Allegaert.txt">
4d9e4936cb44b7c9f17bf264383e5a86c66e4d16
</file>
<file name="get_data\refresh_tokens\Quentin_Caesens.txt">
b6468ebf712a47a1ae12fa4014d46bcb335a4d6e
</file>
<file name="get_data\refresh_tokens\Robbe_Caron.txt">
685027646c6b0f051ee6e9dbfc7a19308ff53446
</file>
<file name="get_data\refresh_tokens\Simon_Plancke.txt">
bff62ed8ee0a75fcb425b965f6b368ab30d47fb5
</file>
<file name="get_data\refresh_tokens\Sofie_Destoop.txt">
2b1db0f45dc5e46ebf00ea417c2fd3d2a1a37086
</file>
<file name="get_data\refresh_tokens\Tanguy_Stienlet.txt">
9045a2400eb050eafa9e00899ed32e81e133f874
</file>
<file name="get_data\refresh_tokens\Thomas_de Coninck.txt">
866691c9679f493c3e1c59a3b8ed8f905029ab59
</file>
<file name="get_data\refresh_tokens\Vincent_Payrat.txt">
ec2c27ff17c73ddd6859f3e49c1b18ccdf06275c
</file>
<file name="get_data\refresh_tokens\William_Bossut.txt">
cd0fd4cc7650e493d1bd4d0fa4fe02d0cc62fbc8
</file>
<file name="get_data\refresh_tokens\󠁧󠁢Michael_Dixon.txt">
8fe1c7111147f9c2489f3355a6402e0fc156e129
</file>
<file name="get_data\src\env_handler.py">
import os
from environs import Env


def _load_env_variables() -&gt; dict:
    # Load environment variables from .env file
    env = Env()
    env.read_env()

    # Get environment variables from .env file
    CLIENT_ID = os.environ.get('CLIENT_ID')
    CLIENT_SECRET = os.environ.get('CLIENT_SECRET')

    env_variables:dict = {
        'CLIENT_ID': CLIENT_ID,
        'CLIENT_SECRET': CLIENT_SECRET
    }

    return env_variables


env_variables = _load_env_variables()

# Function to check if environment variables are set
def check_env_variables(env_variables_list: list) -&gt; [None, ValueError]:
    if None in env_variables_list:
        raise ValueError("Environment variables weren't retrieved properly")


CLIENT_ID = env_variables['CLIENT_ID']
CLIENT_SECRET = env_variables['CLIENT_SECRET']


env_variables_to_check = [
    CLIENT_ID or None,
    CLIENT_SECRET or None
]


check_env_variables(env_variables_to_check)
</file>
<file name="get_data\src\__init__.py">

</file>
<file name="get_data\src\api_methods\authorize.py">
import requests

from src.api_methods import endpoints
from src.env_handler import env_variables


def get_acces_token(refresh_token):
    # these params needs to be passed to get access
    # token used for retrieveing actual data
    payload:dict = {
    'client_id': env_variables['CLIENT_ID'],
    'client_secret': env_variables['CLIENT_SECRET'],
    'refresh_token': refresh_token,
    'grant_type': "refresh_token",
    'f': 'json'
    }
    res = requests.post(endpoints.auth_endpoint, data=payload, verify=False)
    access_token = res.json()['access_token']
    return access_token



</file>
<file name="get_data\src\api_methods\endpoints.py">
auth_endpoint:str = "https://www.strava.com/oauth/token"
activites_endpoint:str = "https://www.strava.com/api/v3/athlete/activities"
</file>
<file name="get_data\src\api_methods\get_methods.py">
import requests

from src.api_methods import endpoints


def access_activity_data(access_token:str, params:dict=None) -&gt; dict:
    headers:dict = {'Authorization': f'Authorization: Bearer {access_token}'}
    if not params:
        response:dict = requests.get(endpoints.activites_endpoint, headers=headers)
    response:dict = requests.get(endpoints.activites_endpoint, headers=headers, params=params)
    response.raise_for_status()
    activity_data = response.json()
    return activity_data
</file>
<file name="get_data\src\api_methods\__init__.py">

</file>
<file name="get_data\src\data_preprocessing\main.py">
import pandas as pd


def preprocess_data(data:dict) -&gt; pd.DataFrame:

    return pd.json_normalize(data)


</file>
<file name="get_data\src\data_preprocessing\__init__.py">

</file>
<file name="get_results\calculate_scores.py">
import os
import pandas as pd
import numpy as np
from datetime import datetime


# -----------------------------------------------------------------
# Set parameters

start_date = '2024-05-06'
end_date = '2024-05-26'

sport_multipliers = {
    'Run': 5,
    'Walk': 5,
    'Hike': 5,
    'Ride': 1,
    'Swim': 25
}

timing_multiplier = 25
# -----------------------------------------------------------------


# -----------------------------------------------------------------
# GENERAL FUNCTIONS

def determine_working_hours(row):
    datetime_obj = datetime.fromisoformat(row[:-1])  # Removing 'Z' from the end
    time = datetime_obj.time()
    day = datetime_obj.date()

    weekday = datetime_obj.weekday()
    if weekday == 5 or weekday == 6:  # Saturday or Sunday
        return 1
    # Public holidays within the competition are considered outside working hours
    elif day.strftime('%Y-%m-%d') in ('2024-05-10', '2024-05-09', '2024-05-20'):
        return 1
    else:    
        if time.hour &gt;= 8 and time.hour &lt; 12:
            return 0
        elif time.hour &gt;= 14 and time.hour &lt; 17:
            return 0
        else:
            return 1

     
def get_relevant_data(row):
    if row['type'] in sport_multipliers.keys():
        sport_multiplier = sport_multipliers[row['type']]
        total_points = (row['distance']/1000*sport_multiplier)
    else:
        total_points = (row['moving_time']/3600*timing_multiplier)

    return total_points

# -----------------------------------------------------------------
        

# -----------------------------------------------------------------
# ORCHESTRATING FUNCTIONS

def get_proper_athletename(athletename):
    if 'MichaelDixon' in athletename:
        athletename = 'MichaelDixon'

    if 'marineLafitau' in athletename:
        athletename = 'MarineLafitau'
    
    return athletename

def create_athlete_dictionnary():
    # Create empty dictionnary
    athletes_dict = {}
    
    # Folder-location of the strava data
    folder_name = 'get_data/data'

    # For each athlete: Get the latest strava extract available in the get_data/data folder
    # Loop over each file in the folder, and extract the name of the athlete and the timestamp from the filename
    # If the athlete is not yet part of the dictionnary: Add athlete-object
    # Else: Check if timestamp is larger than current timestamp assigned to athlete-object. If yes, overwrite
    for file_name in (os.listdir(f'{folder_name}')):
        athlete_name = ''.join(file_name.split('_')[:2])
        timestamp = (file_name.split('_')[2]).split('.')[0]
        
        athlete_name = get_proper_athletename(athlete_name)

        if athlete_name not in athletes_dict.keys():
            athletes_dict[athlete_name] = {'file_name': f'{folder_name}/{file_name}', 'file_timestamp': timestamp}
        elif athletes_dict[athlete_name]['file_timestamp'] &lt; timestamp:
            athletes_dict[athlete_name] = {'file_name': f'{folder_name}/{file_name}', 'file_timestamp': timestamp} 


    # For each athlete-object: Add the multiplier and teamnumber to the dictionnary 
    athlete_info = pd.read_csv('get_results/athlete_info.csv')
    for athlete in athletes_dict:
        print(athlete)

        individual_info = athlete_info[athlete_info['AthleteName'] == athlete]
        # print(individual_info)
        athletes_dict[athlete]['multiplier'] = individual_info['Multiplier'].iloc[0]
        athletes_dict[athlete]['teamnumber'] = individual_info['TeamNumber'].iloc[0]
    
    # Return the dictionnary with athlete-objects looking like:
    '''    
    { 
        [
            athlete_name: {
                "filename": athlete_name_yyyymmddhhMMss.csv
                "timestamp": yyyymmddhhMMss
                "multiplier": x
                "teamnumber": x
                }
            },
            {...}
        ]
    }
    '''
    return athletes_dict


def collect_athlete_data(athletes_dict):

    data_list = []
    for file_name in [athletes_data['file_name'] for athletes_data in athletes_dict.values()]:
        try:
            athlete_df = pd.read_csv(file_name)
            athlete_name_extract = ''.join((file_name.split('/')[-1]).split('_')[:2])
            athlete_name_extract = get_proper_athletename(athlete_name_extract)
            athlete_df['athlete_name'] = athlete_name_extract
            athlete_df['multiplier'] = athletes_dict[athlete_name_extract]['multiplier']
            athlete_df['team_number'] = athletes_dict[athlete_name_extract]['teamnumber']
            athlete_df['outside_working_hours'] = athlete_df['start_date_local'].apply(lambda row: determine_working_hours(row))
            athlete_df['keyrus_coworker'] = np.where(athlete_df['athlete_count'] &gt; 1, 1, 0)
            athlete_df['selfie'] = np.where(athlete_df['photo_count'] == 0, 0, 1)

            athlete_df_subset = athlete_df[(datetime.strptime(start_date, "%Y-%m-%d").date() &lt;= pd.to_datetime(athlete_df['start_date_local']).dt.date) &amp;  (pd.to_datetime(athlete_df['start_date_local']).dt.date &lt;= datetime.strptime(end_date, "%Y-%m-%d").date())]

            data_list.append(athlete_df_subset)
        except:
            print(f"Athlete does not seem to have any activities logged: {file_name}")
        
    # Concatenate all DataFrames in dfs into a single DataFrame
    all_data_dataframe = pd.concat(data_list, ignore_index=True)
    
    return all_data_dataframe



def calculate_activity_points(dataframe):

    dataframe['start_date_date'] = pd.to_datetime(dataframe['start_date_local']).dt.date
    dataframe['total_points'] = dataframe.apply(lambda row: get_relevant_data(row), axis=1)
    relevant_columns = ['distance', 'moving_time', 'type', 'sport_type', 'workout_type', 'id','start_date_date', 'outside_working_hours', 'keyrus_coworker','photo_count', 'athlete_name', 'multiplier', 'team_number', 'selfie', 'total_points']
    relevant_dataframe = dataframe[relevant_columns]

    return relevant_dataframe



def main():
    print("***Start Column Calculations***")

    athlete_dictionnary = create_athlete_dictionnary()
    activity_data = collect_athlete_data(athlete_dictionnary)
    points_dataframe = calculate_activity_points(activity_data)
    points_dataframe.to_csv('get_results/data/calculated_columns.csv')
    
    print("***End Column Calculations***")

if __name__ == '__main__':
    main()
</file>
<file name="get_results\get_sheets.py">
import pandas as pd

# ---------------------------------------------------------------
week_dict = {
    "week_1": {
        "start_date": "2024-05-06",
        "end_date": "2024-05-12"
    },
    "week_2": {
        "start_date": "2024-05-13",
        "end_date": "2024-05-19"
    },
    "week_3": {
        "start_date": "2024-05-20",
        "end_date": "2024-05-26"
    }
}

max_points = 100
# ---------------------------------------------------------------



def get_athlete_point_total(group):
    points_dict = {}
    for week in week_dict:
        subgroup = group.loc[(group['start_date_date'] &gt;= week_dict[week]['start_date']) &amp; (group['start_date_date'] &lt;= week_dict[week]['end_date'])]
        points_dict[week] = ((1+subgroup['outside_working_hours'])*(1+subgroup['keyrus_coworker'])*(subgroup['multiplier'])*subgroup['total_points'] + 5*subgroup['selfie']).sum()
    return points_dict


def calculate_individual_scores(df):

    weekly_athlete_points = df.groupby('athlete_name').apply(lambda group: get_athlete_point_total(group))

    data_list = []
    for name, points_dict in weekly_athlete_points.items():
        data_list.append({
            'athlete_name': name,
            'points_week_1': points_dict.get('week_1', None),
            'points_week_2': points_dict.get('week_2', None),
            'points_week_3': points_dict.get('week_3', None)
        })

    # Convert the list of dictionaries into a DataFrame
    points_dataframe = pd.DataFrame(data_list)
    points_dataframe['total_points'] = points_dataframe[['points_week_1', 'points_week_2', 'points_week_3']].sum(axis=1)

    to_merge = df.groupby('athlete_name', as_index=False)[['multiplier', 'team_number']].first() # multiplier,team_number
    points_dataframe = points_dataframe.merge(to_merge, on='athlete_name', how='left')
    # print(name)
    #print(points_dataframe)
    return points_dataframe


def get_max_team_score(weekly_team_member):
    weekly_team_member['selfie'].replace(1.0, 0.5, inplace=True)
    weekly_team_member['benefits'] = weekly_team_member['keyrus_coworker'] + weekly_team_member['selfie'] + weekly_team_member['outside_working_hours']
    
    #weekly_team_member['Total_Rebalanced_Points'] = weekly_team_member.apply(lambda row: calculate_total_rebalanced_points(row), axis = 1) 
    weekly_team_member = weekly_team_member.sort_values(by=['benefits', 'total_points'], ascending=(False, False))
    #if name == 'Simon Plancke': print(weekly_team_member)

    individual_points = 0
    multiplier_points = 0
    for i in range(0,len(weekly_team_member)):
        activity_points = (1+weekly_team_member.iloc[i]['outside_working_hours'])*(1+weekly_team_member.iloc[i]['keyrus_coworker'])*(int(weekly_team_member.iloc[i]['multiplier']))*weekly_team_member.iloc[i]['total_points'] + 5*weekly_team_member.iloc[i]['selfie']
        individual_points +=  weekly_team_member.iloc[i]['total_points']
        #if name == 'Simon Plancke': print(individual_points, multiplier_points)
        if individual_points &gt; max_points:
            individual_points = individual_points - weekly_team_member.iloc[i]['total_points']
            x = (max_points - individual_points)/weekly_team_member.iloc[i]['total_points']
            if weekly_team_member.iloc[i]['selfie'] == 0.5:
                multiplier_points = multiplier_points + (activity_points-5)*x +5
            else:
                multiplier_points = multiplier_points + activity_points*x
            individual_points = individual_points + weekly_team_member.iloc[i]['total_points']*x
            #if name == 'Simon Plancke': print(individual_points, multiplier_points, x)
            break
        else:
            multiplier_points = multiplier_points + activity_points
            #if name == 'Simon Plancke': print(individual_points, multiplier_points)
    return multiplier_points

def get_member_point_total(team_member):
    #print(team_member)
    points_dict = {}
    for week in week_dict:
        subgroup = team_member.loc[(team_member['start_date_date'] &gt;= week_dict[week]['start_date']) &amp; (team_member['start_date_date'] &lt;= week_dict[week]['end_date'])]
        if subgroup['total_points'].sum() &lt; max_points:
            points_dict[week] = ((1+subgroup['outside_working_hours'])*(1+subgroup['keyrus_coworker'])*subgroup['total_points'] + 5*subgroup['selfie']).sum()

        else:
            points_dict[week] = get_max_team_score(subgroup)
    return points_dict

def get_group_point_total(group):
    team_total_dict = group.groupby('athlete_name').apply(lambda group: get_member_point_total(group))
    # print(group)
    team_total = []
    for team_member, points_dict in team_total_dict.items():
        team_total.append({
            'team_member': team_member,
            'points_week_1': points_dict.get('week_1', None),
            'points_week_2': points_dict.get('week_2', None),
            'points_week_3': points_dict.get('week_3', None)
        })
    
    team_total_dataframe = pd.DataFrame(team_total)
    team_total_dataframe['total_points'] = team_total_dataframe[['points_week_1', 'points_week_2', 'points_week_3']].sum(axis=1)
    # print(team_total_dataframe)
    return team_total_dataframe

def calculate_team_scores(df):
    weekly_team_member_df = df.groupby('team_number').apply(lambda group: get_group_point_total(group))

    group_scores = []
    for team_number, group in weekly_team_member_df.groupby('team_number'):
        # print(team_number)
        # print(group)
        group_scores.append({
            'team_number': team_number,
            'points_week_1': group['points_week_1'].sum(),
            'points_week_2': group['points_week_2'].sum(),
            'points_week_3': group['points_week_3'].sum(),
            'total_points':  group['total_points'].sum()
        })
    
    group_scores_dataframe = pd.DataFrame(group_scores)
    # print(group_scores_dataframe)
    return group_scores_dataframe


def write_to_individual_files(dataframe):
    print(dataframe)
    grouped_multiplier = dataframe.groupby('multiplier')
    for week in week_dict:
        with pd.ExcelWriter("get_results/data/Individual_Ranking.xlsx",mode='a', if_sheet_exists='replace') as writer:
            for multiplier, group in grouped_multiplier:
                columns = ['athlete_name', f'points_{week}', 'multiplier']
                group = group[columns].sort_values(f'points_{week}', ascending=False)
                group.to_excel(writer, sheet_name=f'{week}_multiplier_{str(multiplier)}', columns=list(group.columns.values), header=True, index=False, startrow=0, startcol=0)

    with pd.ExcelWriter("get_results/data/Individual_Ranking.xlsx",mode='a', if_sheet_exists='replace') as writer:
        for multiplier, group in grouped_multiplier:
            columns = ['athlete_name', 'total_points', 'multiplier']
            group = group[columns].sort_values('total_points', ascending=False)
            group.to_excel(writer, sheet_name=f'Final_multiplier_{str(multiplier)}', columns=list(group.columns.values), header=True, index=False, startrow=0, startcol=0)

    return

def write_to_group_files(dataframe):

    with pd.ExcelWriter("get_results/data/Team_Ranking.xlsx",mode='a', if_sheet_exists='replace') as writer:
        dataframe.to_excel(writer, sheet_name=f'Team_Standings', columns=list(dataframe.columns.values), header=True, index=False, startrow=0, startcol=0)

    return

def main():
    print("***Start Column Calculations***")

    automated_scores = pd.read_csv('get_results/data/calculated_columns.csv')
    manual_scores = pd.read_csv('get_results/data/manually_calculated_columns.csv')
    total_scores = pd.concat([automated_scores, manual_scores])
    # print(total_scores)
    weekly_individual_scores = calculate_individual_scores(total_scores)
    # print(weekly_individual_scores)
    write_to_individual_files(weekly_individual_scores)
    weekly_group_scores = calculate_team_scores(total_scores)
    write_to_group_files(weekly_group_scores)
    print("***End Column Calculations***")

if __name__ == '__main__':
    main()
</file>
<file name="get_results\request_axel.py">
import pandas as pd



def main():
    print("***Start Column Calculations***")

    automated_scores = pd.read_csv('get_results/data/calculated_columns.csv')
    manual_scores = pd.read_csv('get_results/data/manually_calculated_columns.csv')
    total_scores = pd.concat([automated_scores, manual_scores])
    # # print(total_scores)
    # bike_activities = total_scores[total_scores['type'] == 'Ride']
    # # print(bike_activities)
    # total_bike_kms = (bike_activities['distance'].sum())/1000
    # print(total_bike_kms)
    # total_number_cyclists = total_scores['type'].unique()
    # print(total_number_cyclists)
    # average_cycle_distance = total_bike_kms/len(total_number_cyclists)
    # print(average_cycle_distance)
    print("Total number of activities: ", total_scores['total_points'].count())
    total_converted_kms = total_scores['total_points'].sum()
    print("Total converted kms: ",total_converted_kms)

    bike_activities = total_scores[total_scores['type'].isin(['Ride', 'VirtualRide', 'EBikeRide'])]
    total_ride_kms = (bike_activities['distance'].sum())/1000
    print("Total cycling kms: ",total_ride_kms)

    walk_activities = total_scores[total_scores['type'].isin(['Walk', 'Hike'])]
    total_walk_kms = (walk_activities['distance'].sum())/1000
    print("Total walking kms: ",total_walk_kms)

    swim_activities = total_scores[total_scores['type'] == 'Swim']
    total_swim_kms = (swim_activities['distance'].sum())/1000
    print("Total swimming kms: ",total_swim_kms)

    run_activities = total_scores[total_scores['type'] == 'Run']
    total_run_kms = (run_activities['distance'].sum())/1000
    print("Total running kms: ",total_run_kms)

    workout_activities = total_scores[total_scores['type'].isin(['Workout', 'WeightTraining', 'RockClimbing', 'Crossfit', 'Yoga', 'Golf', 'Soccer', 'Elliptical'])]
    total_workout_hours = (workout_activities['moving_time'].sum())/3600
    print("Total hours worked out: ",total_workout_hours)
    
    print("***End Column Calculations***")

if __name__ == '__main__':
    main()
</file>
<file name="get_token\login.py">
from selenium import webdriver
from selenium.webdriver.common.by import By
from urllib.parse import urlparse
import requests
import json
from pause import sleep

# Find the username and password input fields and login button
# username_field = browser.find_element(By.ID, 'email')  # Replace 'username' with the actual ID of the username field
# password_field = browser.find_element(By.ID, 'password')  # Replace 'password' with the actual ID of the password field
# login_button = browser.find_element(By.ID, 'login-button')  # Replace 'login-btn' with the actual ID of the login button

# Enter your username and password
# username_field.send_keys(input("Give your strava login or email address: "))
# # password_field.send_keys(input("Give your strava password: "))
# import maskpass
# password_field.send_keys(maskpass.askpass(prompt="Give your strava password:", mask="*"))

# Click the login button
# login_button.click()

# Set environment variables
#chrome_driver_path = 'C:\Program Files (x86)\Google\Chrome\Application\chrome.exe'  # Replace 'path_to_chromedriver' with the actual path to chromedriver
client_id = 105125
client_secret = '258981ce6d5eea7d02c898b98d8d4f3098395060'


def strava_login():

    # Launch Chrome browser
    options = webdriver.ChromeOptions()
    options.add_argument("--start-maximized")  # Maximize the browser window on start
    browser = webdriver.Chrome(options=options)

    # Open the Strava login screen
    login_url = "https://www.strava.com/login"
    browser.get(login_url)

    # Wait for user to login
    waitTime = 10 # Number of seconds to wait in between each 'ping' to the server
    maxTries = 12 # Maximal number of 'pings' that will be send to the server. Once exceeded, code will stop and throw error

    numTries = 0 # Initialize total number of tries

    # While the 'login-button' still exists:
    #   Check if numTries &lt; maxTries -&gt; Wait if true, break if false
    while browser.find_elements(By.ID, 'login-button'):
        if numTries &lt; maxTries:
            print("Waiting for user input...")
            sleep(waitTime)
            numTries += 1
        else:
            raise ValueError("Took too long to login. Process has stopped.")

    # Wait for the login process to complete (page will need to refresh after logging in)
    browser.implicitly_wait(10)
    return browser

def authorize_api(browser):
    # Connect to the Keyrus Sports Competition API client
    url = f"https://www.strava.com/oauth/authorize?client_id={client_id}&amp;response_type=code&amp;redirect_uri=http://localhost/exchange_token&amp;approval_prompt=force&amp;scope=activity:read_all"

    # Use the Chrome browser, where the user just logged in, to surf to the API Authorization screen
    browser.get(url)

    # Find the 'Authorize' button on the screen
    authorize_button = browser.find_element(By.ID, 'authorize')
    # If the button is found:
    if authorize_button:
        authorize_button.click()                    # Click the 'authorize' button
        browser.implicitly_wait(10)                 # Wait 10 seconds for the screen to refresh
        redirected_url = browser.current_url        # Get the url of the new page
        browser.quit()                              # Close the browser

        # print("Authorize URL:", redirected_url)     # Print the redirected URL: http://localhost/exchange_token?state=&amp;code={temporary_accesstoken}&amp;scope=read,activity:read_all

        parsed_url = urlparse(redirected_url)       # Parse the URL into sections

        # From the parsed url:
        #   Get the query-section
        #   Each filter in the query-section is split by the '&amp;' symbol
        #   Return a dictionary with the keys and values for each filter
        filter_dict = dict(filter.split("=") for filter in (parsed_url.query).split("&amp;"))
        # Return the value for the code-filter (which is the access_token used to access the strava account)
        return filter_dict['code']
    
    # If the button is not found: Throw error
    else:
        raise ValueError("No authorization button found. Something went wrong...")


def get_refreshtoken(accesstoken):
    # Use the access_token to get the refresh_token

    # Define the URL and payload
    url = "https://www.strava.com/oauth/token"
    payload = {
        "client_id": client_id,
        "client_secret": client_secret,
        "code": accesstoken,
        "grant_type": "authorization_code"
    }

    # Send the POST request
    response = requests.post(url, data=payload)

    # The POST request should return a JSON-object with information about the strava account
    # Loop over the JSON-object 
    for key, value in (json.loads(response.text)).items():
        # If the refresh_token key is found, store its value in a variable
        if key == 'refresh_token':
            refresh_token = value
        # If the athlete-key is found, loop over the object
        if key == 'athlete':
            for athlete_key, athlete_value in value.items():
                # Store the first and last name of the athlete in a variables
                if athlete_key == 'firstname':
                    firstname = athlete_value
                elif athlete_key == 'lastname':
                    lastname = athlete_value
    
    # Write the refresh_token over the athlete to a txt-file named 'firstname_lastname.txt'
    file = open(f'get_token/{firstname}_{lastname}.txt', 'w')
    file.write(refresh_token)
    file.close()
    return

def main():
    print("***Start Login Process***")

    browser = strava_login()
    accesstoken = authorize_api(browser)
    get_refreshtoken(accesstoken)

if __name__ == '__main__':
    main()
</file>
<file name="get_token\requirements.txt">
selenium==4.18.0
requests==2.28.1
pause==0.3
</file>
<file name="get_token\Simon_Plancke.txt">
bff62ed8ee0a75fcb425b965f6b368ab30d47fb5
</file>
</source>